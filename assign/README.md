# Assign data for annotation

## Pilot data
`pilot_{bge_small, openai_small}.jsonl`: Small samples for pilot, embedded by different embedders. The `sample_id` field is the index of the sample in the original dataset. 

## Real annotation 
Under folder `batch_5_src_no_sports`. 5 sources per batch. A total 50 samples per batch.  No Sports articles. 


## File Description
### Data Files
- **`examples_to_annotate.csv`**  
  - Contains all samples used in the first phase of annotation.  
  - **Generated by**: `../data_collection_scripts/select_hard_examples.ipynb`  
  - **Selection criteria**: Source documents that appear at least 5 times in disagreed examples.

- **`examples_to_annotate2.csv`**  
  - Contains additional samples used in the first phase of annotation.  
  - **Generated by**: `../data_collection_scripts/select_hard_examples.ipynb`  
  - **Selection criteria**: Source documents that appear 3â€“4 times in disagreed examples.

- **`FaithBench.csv`**  
  - The final dataset after the first phase of annotation, containing 800 samples.  
  - **Fields**:  
    - `source`: Original document text.  
    - `summary`: Generated summary.  
    - `LLM`: Language model responsible for the summary.  
    - `worst-label`: Human annotation result using "worst-pooling".  
    - `best-label`: Human annotation result using "best-pooling".  
  - **Source**: `source`, `summary`, and `LLM` fields are derived from [Vectara HHEM Leaderboard Results](https://huggingface.co/datasets/vectara/leaderboard_results).  
  - **Generated by**: `generate_faithbench.ipynb`.

---

### Scripts
- **`create_batch.ipynb`**  
  - Notebook for creating annotation batches.

- **`annotation_config.py`**  
  - Configuration file for loading and filtering annotations.

- **`generate_faithbench.ipynb`**
  - Notebook for generating `FaithBench.csv` based on all annotations without filtering

- **`dataset_stats.ipynb`**
  - Script for getting basic statistics of dataset