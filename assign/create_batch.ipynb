{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "df = pd.read_csv('examples_to_annotate.csv')\n",
    "df['sample_id'] = df.index\n",
    "skip_idx = []\n",
    "data = []\n",
    "# for pilot_file in ['pilot_bge_small.jsonl', 'pilot_openai_small.jsonl']:\n",
    "#     with jsonlines.open(pilot_file) as reader:\n",
    "#         for obj in reader:\n",
    "#             data.append(obj)\n",
    "\n",
    "# pilot_df = pd.DataFrame(data).drop_duplicates()\n",
    "# skip_idx = pilot_df['sample_id'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sports_idx = [0, 22, 23, 25, 27, 28, 33, 35, 37, 38, 39, 43, 44, 45, 48, 50, 51, 57, 58, 65, 68, 97, 98, 99, 100, 101, 102, 103, 107, 108, 115, 137, 138, 140, 142, 143, 148, 150, 152, 153, 154, 158, 159, 160, 163, 165, 166, 172, 173, 180, 183, 212, 213, 214, 215, 216, 217, 218, 222, 223, 230, 252, 253, 255, 257, 258, 263, 265, 267, 268, 269, 273, 274, 275, 278, 280, 281, 287, 288, 295, 298, 327, 328, 329, 330, 331, 332, 333, 337, 338, 345, 367, 368, 370, 372, 373, 378, 380, 382, 383, 384, 388, 389, 390, 393, 395, 396, 402, 403, 410, 413, 442, 443, 444, 445, 446, 447, 448, 452, 453, 460, 482, 483, 485, 487, 488, 493, 495, 497, 498, 499, 503, 504, 505, 508, 510, 511, 517, 518, 525, 528, 557, 558, 559, 560, 561, 562, 563, 567, 568, 575, 597, 598, 600, 602, 603, 608, 610, 612, 613, 614, 618, 619, 620, 623, 625, 626, 632, 633, 640, 643, 672, 673, 674, 675, 676, 677, 678, 682, 683, 690, 712, 713, 715, 717, 718, 723, 725, 727, 728, 729, 733, 734, 735, 738, 740, 741, 747, 748, 755, 758, 787, 788, 789, 790, 791, 792, 793, 797, 798, 805, 827, 828, 830, 832, 833, 838, 840, 842, 843, 844, 848, 849, 850, 853, 855, 856, 862, 863, 870, 873, 902, 903, 904, 905, 906, 907, 908, 912, 913, 922, 924, 925, 928, 936, 941, 945, 950, 955, 956, 957, 958, 959, 960, 961, 964, 971, 975, 977, 978, 1003, 1004, 1005, 1015, 1016, 1017, 1018, 1020, 1023, 1027, 1035, 1057, 1058, 1060, 1062, 1063, 1068, 1070, 1072, 1073, 1074, 1078, 1079, 1080, 1083, 1085, 1086, 1092, 1093, 1100, 1103, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1142, 1143]\n",
    "# skip_idx += sports_idx\n",
    "# skip_idx = set(skip_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    return len(str(text).split())\n",
    "\n",
    "df_after_skip = df.drop(index=skip_idx)\n",
    "df_after_skip['word_count'] = df_after_skip['source'].apply(count_words)\n",
    "\n",
    "# Step 1: Group by source_doc and get one representative record for each source_doc (to get its word count)\n",
    "sorted_df = df_after_skip.groupby('source').apply(lambda x: x.head(1))\n",
    "\n",
    "# Step 2: Sort the source documents based on their word count\n",
    "sorted_source_docs = sorted_df.sort_values(by='word_count')['source']\n",
    "# print(sorted_source_docs.shape) # 115\n",
    "\n",
    "# Step 3: Create batches of 10 records for each source document, sorted by word count of the source document\n",
    "for batch_idx, doc in enumerate(sorted_source_docs):\n",
    "    batch = df[df['source'] == doc]\n",
    "    batch.to_json(f\"batch_files/batch{batch_idx}.jsonl\", orient='records', lines=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
