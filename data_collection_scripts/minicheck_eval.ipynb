{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miaoran/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Generator, Protocol, List, Tuple\n",
    "import pandas as pd\n",
    "# import nltk\n",
    "# nltk.download('punkt_tab')\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "from minicheck.minicheck import MiniCheck\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinicheckEval(filename, model_name, col_name = None, update=True, batch_size=20, outputfile=None):\n",
    "    df = pd.read_csv(filename, encoding='utf-8').fillna('')\n",
    "    if not col_name:\n",
    "        col_name = f'minicheck-{model_name}'\n",
    "    if (not update) and (col_name in df): # store HHEM scores\n",
    "        return\n",
    "    model = MiniCheck(model_name=model_name, cache_dir='./ckpts')\n",
    "    scores = []\n",
    "    n = len(df['source'].tolist())\n",
    "    for i in range(0,n,batch_size):\n",
    "        pred_label, raw_prob, _, _ = model.score(docs=df['source'].tolist()[i:i+batch_size], claims=df['summary'].tolist()[i:i+\n",
    "                                                                                                                           batch_size])\n",
    "        scores.extend(pred_label)\n",
    "    if col_name in df:\n",
    "        df[col_name] = scores\n",
    "    else:\n",
    "        df.insert(len(df.columns), col_name, scores)\n",
    "    if not outputfile:\n",
    "        outputfile = filename\n",
    "    df.to_csv(outputfile, mode='w', index=False, header=True)\n",
    "    print(f'Minicheck {model_name} Scores have been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run model 0: roberta-large ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 27.86it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.26it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.94it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 21.50it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.69it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 17.32it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 35.31it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.64it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 20.82it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.53it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.83it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 23.51it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 29.44it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.73it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 22.06it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.34it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 16.35it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 37.16it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 26.44it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.21it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 20.28it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 21.48it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 16.19it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 49.36it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.64it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.38it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 22.25it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 20.02it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 17.48it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 41.09it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.65it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 21.23it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.83it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.94it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 22.75it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 30.27it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.80it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 22.36it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.50it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 16.42it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 37.00it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 26.46it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.39it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 20.57it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 21.72it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 16.27it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 26.01it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 21.97it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 21.66it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 27.48it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 16.55it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.64it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 39.04it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 19.57it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:00<00:00, 20.75it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.66it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 18.92it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minicheck roberta-large Scores have been saved\n",
      "Run model 1: deberta-v3-large ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:49<00:00,  2.48s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:48<00:00,  2.43s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:40<00:00,  2.01s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:45<00:00,  2.27s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:53<00:00,  2.66s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:17<00:00,  1.14it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:46<00:00,  2.32s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:41<00:00,  2.07s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:48<00:00,  2.41s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:45<00:00,  2.25s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:37<00:00,  1.85s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:28<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:51<00:00,  2.60s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:39<00:00,  1.98s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:51<00:00,  2.57s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:57<00:00,  2.88s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:29<00:00,  1.46s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:45<00:00,  2.28s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:41<00:00,  2.07s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:36<00:00,  1.85s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:49<00:00,  2.45s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:41<00:00,  2.09s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:44<00:00,  2.22s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:34<00:00,  1.75s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:38<00:00,  1.90s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:47<00:00,  2.37s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:16<00:00,  1.21it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:43<00:00,  2.19s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:38<00:00,  1.94s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:45<00:00,  2.30s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:42<00:00,  2.13s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:33<00:00,  1.69s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:26<00:00,  1.30s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:46<00:00,  2.31s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:37<00:00,  1.87s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:47<00:00,  2.36s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:51<00:00,  2.59s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:28<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:43<00:00,  2.16s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:39<00:00,  1.95s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:35<00:00,  1.76s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:48<00:00,  2.44s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:28<00:00,  1.42s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:35<00:00,  1.79s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:35<00:00,  1.78s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:29<00:00,  1.49s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:52<00:00,  2.63s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:39<00:00,  1.96s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:17<00:00,  1.17it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:43<00:00,  2.18s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:39<00:00,  1.99s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:45<00:00,  2.25s/it]\n",
      "Evaluating: 100%|██████████| 20/20 [00:41<00:00,  2.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:26<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minicheck deberta-v3-large Scores have been saved\n",
      "Run model 2: flan-t5-large ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 14.26it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.64it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.18it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.40it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.35it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  8.29it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 14.57it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.03it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.93it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.26it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.03it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.28it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 12.68it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.16it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.29it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.13it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  8.79it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 13.22it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 12.28it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.68it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.04it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 11.01it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  8.99it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 15.92it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.33it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.83it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 11.10it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 11.16it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  8.84it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 14.65it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.40it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.19it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.43it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.38it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.59it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 12.85it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.77it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.44it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.10it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 13.38it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 12.49it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.88it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.28it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 11.00it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  8.94it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 13.02it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.74it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 12.14it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  8.52it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.34it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 14.85it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.17it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.86it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:02<00:00,  9.50it/s]\n",
      "Evaluating: 100%|██████████| 20/20 [00:01<00:00, 10.26it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minicheck flan-t5-large Scores have been saved\n"
     ]
    }
   ],
   "source": [
    "minicheck_models = ['roberta-large', 'deberta-v3-large', 'flan-t5-large']#, 'Bespoke-MiniCheck-7B']\n",
    "# selected_models = [\n",
    "#     \"openai/GPT-3.5-Turbo\",\n",
    "#     \"openai/gpt-4o\",\n",
    "#     \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "#     \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     \"cohere/command-r-08-2024\",\n",
    "#     \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "#     \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "#     \"google/gemini-1.5-flash-001\",\n",
    "#     \"Anthropic/claude-3-5-sonnet-20240620\",\n",
    "#     \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "# ]\n",
    "# for idx, minichecker in enumerate(minicheck_models):\n",
    "#     print(f\"Run model {str(idx)}: {minichecker} ......\")\n",
    "#     for model_name in selected_models:\n",
    "#         filename = f\"../backup_data_with_detector_results/{model_name}.csv\"\n",
    "#         print(f\"Processing P{model_name}\")\n",
    "    \n",
    "#         MinicheckEval(filename, minichecker, update=False)\n",
    "\n",
    "for idx, minichecker in enumerate(minicheck_models):\n",
    "    print(f\"Run model {str(idx)}: {minichecker} ......\")\n",
    "    filename = f\"../assign/examples_to_annotate.csv\"\n",
    "    MinicheckEval(filename, minichecker, update=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
